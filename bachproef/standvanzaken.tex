\chapter{\IfLanguageName{dutch}{Stand van zaken}{State of the art}}%
\label{ch:stand-van-zaken}

% Tip: Begin elk hoofdstuk met een paragraaf inleiding die beschrijft hoe
% dit hoofdstuk past binnen het geheel van de bachelorproef. Geef in het
% bijzonder aan wat de link is met het vorige en volgende hoofdstuk.

% Pas na deze inleidende paragraaf komt de eerste sectiehoofding.

In de digitale wereld van vandaag is data de sleutel tot succes. Bedrijven verzamelen en ana-lyseren data om hun klanten beter te begrijpen, hun marketingstrategieën te optimaliseren, en hun concurrentiepositie te versterken \autocite{},
Deze enorme vraag naar kwalitatieve data drijftde ontwikkeling van nieuwe en innovatieve me-thodes voor dataverzameling. Er zijn vele manie-ren waarop er aan dataverzameling kan gedaan worden, deze studie focussed zich op webscra-ping.

\section{Webscraping}
Webscraping is een techniek die automatisch
data extraheert van websites. Deze data kan in
verschillende formaten voorkomen, zoals HTML,
JSON, XML en CSV. Webscraping heeft tal van toepassingen,
waaronder:
\begin{itemize}
    \item Data-extractie, dit is het verzamelen van data van websites voor diverse doeleinden,
    zoals marktonderzoek,prijsvergelijking en het verzamelen van recensies
    \item Het automatiseren van taken die anders handmatig zouden moeten worden uitgevoerd, denk maar
    aan het invullen van bepaalde formulieren, aanmaken van documenten en downloaden van bestanden
    \item Monitoren van websites voor veranderingen van prijzen, nieuwe producten of statussen van bepaalde zaken
\end{itemize}

\subsection{Traditionele webscraping}

In dit hoofdstuk wordt traditionele webscraping  onderzocht als een techniek voor het extraheren van data van websites door het parsen van de HTML-code van websites. De focus ligt op het begrijpen van de werking van traditionele webscraping, het identificeren van de voor- en nadelen ervan, en het verkennen van enkele alternatieve methoden.

Traditionele webscraping begint met het identificeren van de doelpagina die de gewenste data bevat. Vervolgens wordt de HTML-code van de doelpagina opgehaald via een HTTP-request. Deze stap kan worden uitgevoerd met de developer tools  in de browser, Postman of met de een van de meest gebruikte libraries van Python: requests \autocite{Nate2023}.  Na het verkrijgen van de HTML-code wordt deze geparsd om er de gewenste gegevens uit te halen. Dit kan gedaan worden met de Python library BeautifulSoup. De verkregen data kan daarna worden omgezet in verschillende data formaten zoals JSON, CSV en XML of het kan rechtstreeks  in een database of een ander bestandssysteem gestoken worden.

Enkele voordelen van de traditionele webscraping manier zijn:
\begin{itemize}
    \item Eenvoudig: Traditionele webscraping is een van de eenvoudigere methodes die met weinig technische kennis kan worden toegepast. Op fora zoals StackOverflow
\end{itemize}


\subsection{Netwerkverkeersanalyse}

Netwerkverkeersanalyse, ook wel packet capture of network sniffing genoemd, is een techniek waarbij datapakketten die over een computernetwerk reizen worden geanalyseerd \autocite{Chapple2018}.  In tegenstelling tot traditionele webscraping methoden die de HTML-code van webpagina’s parsen, richt deze methode zich op de data die wordt uitgewisseld tussen de client en de server. Het analyseren van netwerkverkeer is efficiënter dan het parsen van HTML-code.  De
data die via netwerkverkeersanalyse wordt geëxtraheerd is vaak al gestructureerd en geformatteerd, waardoor het eenvoudiger te verwerken is.
Deze methode is in tegenstelling tot de traditionele manier veel flexibeler omdat er niet naar de
HTML-code wordt gekeken maar wel naar het verkeer en dus de data die verstuurd wordt. Dit wil
zeggen dat de scrapers nog steeds zullen werken
ook als de website geupdate wordt. Websites implementeren steeds vaker anti-scraping maatregelen om te voorkomen dat hun data wordt gescraped. Netwerkverkeersanalyse is minder gevoelig voor deze maatregelen, omdat het de data
extraheert voordat deze door de website wordt
geladen. De analyse van netwerkverkeer is
complexer dan de traditionele webscraping methoden. Het vereist meer technische kennis om
de data te onderscheppen,te interpreteren en te
verwerken. Soms versleutelen websites hun netwerkverkeer, waardoor het moeilijker of zelfs onmogelijk is om data te extraheren. Een aantal tools die hiervoor kan gebruikt worden is Wireshark,
dit is een opensource tool met een breed scala
aan funties voor het vastleggen van allerlei soorten netwerkverkeer. Ook de python libraries ’scapy’
en ’mitmproxy’ bieden krachtige tools voor het
analyseren en manipuleren van netwerkverkeer.
